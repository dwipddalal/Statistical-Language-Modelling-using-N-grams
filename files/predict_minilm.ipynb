{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering,AutoModel,AutoConfig\n",
    "from transformers import AutoTokenizer,AutoModelForQuestionAnswering, TrainingArguments, Trainer,AutoConfig,AutoModel\n",
    "from transformers import DefaultDataCollator\n",
    "from transformers import TrainingArguments\n",
    "from transformers import HfArgumentParser\n",
    "from transformers import Trainer\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "from transformers import DistilBertModel\n",
    "from datasets import load_dataset\n",
    "from transformers import PreTrainedModel,PretrainedConfig\n",
    "from transformers.modeling_outputs import QuestionAnsweringModelOutput\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import collections\n",
    "from datasets import DatasetDict\n",
    "import ast\n",
    "from transformers import EarlyStoppingCallback\n",
    "from tqdm import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "para = \"Tennis is a racket sport that is played either individually against a single opponent (singles) or between two teams of two players each (doubles). Each player uses a tennis racket that is strung with cord to strike a hollow rubber ball covered with felt over or around a net and into the opponent's court. The object of the game is to manoeuvre the ball in such a way that the opponent is not able to play a valid return. The player who is unable to return the ball validly will not gain a point, while the opposite player will.\"\n",
    "question = \"What is the ball made of?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Metric calculation taken from https://rajpurkar.github.io/SQuAD-explorer/\n",
    "def normalize_answer(s):\n",
    "  \"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"\n",
    "  def remove_articles(text):\n",
    "    regex = re.compile(r'\\b(a|an|the)\\b', re.UNICODE)\n",
    "    return re.sub(regex, ' ', text)\n",
    "  def white_space_fix(text):\n",
    "    return ' '.join(text.split())\n",
    "  def remove_punc(text):\n",
    "    exclude = set(string.punctuation)\n",
    "    return ''.join(ch for ch in text if ch not in exclude)\n",
    "  def lower(text):\n",
    "    return text.lower()\n",
    "  return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
    "\n",
    "def get_tokens(s):\n",
    "  if not s: return []\n",
    "  return normalize_answer(s).split()\n",
    "\n",
    "def compute_f1(a_gold, a_pred):\n",
    "  gold_toks = get_tokens(a_gold)\n",
    "  pred_toks = get_tokens(a_pred)\n",
    "  common = collections.Counter(gold_toks) & collections.Counter(pred_toks)\n",
    "  num_same = sum(common.values())\n",
    "  if len(gold_toks) == 0 or len(pred_toks) == 0:\n",
    "    # If either is no-answer, then F1 is 1 if they agree, 0 otherwise\n",
    "    return int(gold_toks == pred_toks)\n",
    "  if num_same == 0:\n",
    "    return 0\n",
    "  precision = 1.0 * num_same / len(pred_toks)\n",
    "  recall = 1.0 * num_same / len(gold_toks)\n",
    "  f1 = (2 * precision * recall) / (precision + recall)\n",
    "  return f1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load through Pipline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline(\"question-answering\", model=\"/home/vp.shivasan/interiit/task2/training_dir/task2_MiniLM-mod_50epochs_2e-5_FINAL_ES/checkpoint-5076\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load from base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = AutoTokenizer.from_pretrained(\"microsoft/MiniLM-L12-H384-uncased\")\n",
    "# config = AutoConfig.from_pretrained(\"microsoft/MiniLM-L12-H384-uncased\")#AutoConfig.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "class MiniLMQA(PreTrainedModel):\n",
    "    def __init__(self,config: PretrainedConfig):\n",
    "        # super(DistillBERTQA, config).__init__()\n",
    "        super().__init__(config)\n",
    "        self.MiniLM = AutoModel.from_pretrained(\"microsoft/MiniLM-L12-H384-uncased\") #DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "        self.qa_outputs = torch.nn.Linear(384, 2)\n",
    "        self.dropout = torch.nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, input_ids=None, attention_mask=None,start_positions=None,end_positions=None,return_dict=None):\n",
    "        minilm_output = self.MiniLM(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        hidden_states = minilm_output[0]\n",
    "        hidden_states = self.dropout(hidden_states)\n",
    "        logits = self.qa_outputs(hidden_states)\n",
    "        start_logits, end_logits = logits.split(1, dim=-1)\n",
    "        start_logits = start_logits.squeeze(-1).contiguous()  # (bs, max_query_len)\n",
    "        end_logits = end_logits.squeeze(-1).contiguous()  # (bs, max_query_len)\n",
    "        total_loss = None\n",
    "        if start_positions is not None and end_positions is not None:\n",
    "            # If we are on multi-GPU, split add a dimension\n",
    "            if len(start_positions.size()) > 1:\n",
    "                start_positions = start_positions.squeeze(-1)\n",
    "            if len(end_positions.size()) > 1:\n",
    "                end_positions = end_positions.squeeze(-1)\n",
    "            # sometimes the start/end positions are outside our model inputs, we ignore these terms\n",
    "            ignored_index = start_logits.size(1)\n",
    "            start_positions = start_positions.clamp(0, ignored_index)\n",
    "            end_positions = end_positions.clamp(0, ignored_index)\n",
    "\n",
    "            loss_fct = torch.nn.CrossEntropyLoss(ignore_index=ignored_index)\n",
    "            start_loss = loss_fct(start_logits, start_positions)\n",
    "            end_loss = loss_fct(end_logits, end_positions)\n",
    "            total_loss = (start_loss + end_loss) / 2\n",
    "\n",
    "        if not return_dict:\n",
    "            output = (start_logits, end_logits) + minilm_output[1:]\n",
    "            return ((total_loss,) + output) if total_loss is not None else output\n",
    "\n",
    "        return QuestionAnsweringModelOutput(\n",
    "            loss=total_loss,\n",
    "            start_logits=start_logits,\n",
    "            end_logits=end_logits,\n",
    "            hidden_states=minilm_output.hidden_states,\n",
    "            attentions=minilm_output.attentions,\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('/home/vp.shivasan/interiit/task2/training_dir/task2_MiniLM-mod_50epochs_2e-5_FINAL_ES/checkpoint-5076')\n",
    "config = AutoConfig.from_pretrained('/home/vp.shivasan/interiit/task2/training_dir/task2_MiniLM-mod_50epochs_2e-5_FINAL_ES/checkpoint-5076')\n",
    "model = MiniLMQA(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict = torch.load('/home/vp.shivasan/interiit/task2/training_dir/task2_MiniLM-mod_50epochs_2e-5_FINAL_ES/checkpoint-5076/pytorch_model.bin')\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = r\"\"\"\n",
    "# 🤗 The NES uses a custom-made Picture Processing Unit (PPU) developed by Ricoh. All variations of the PPU feature 2 kB of video RAM, 256 bytes of on-die \"\"object attribute memory\"\" (OAM) to store the positions, colors, and tile indices of up to 64 sprites on the screen, and 28 bytes of on-die palette RAM to allow selection of background and sprite colors. The console's 2 kB of onboard RAM may be used for tile maps and attributes on the NES board and 8 kB of tile pattern ROM or RAM may be included on a cartridge. The system has an available color palette of 48 colors and 6 grays. Up to 25 simultaneous colors may be used without writing new values mid-frame: a background color, four sets of three tile colors and four sets of three sprite colors. The NES palette is based on NTSC rather than RGB values. A total of 64 sprites may be displayed onscreen at a given time without reloading sprites mid-screen. The standard display resolution of the NES is 256 horizontal pixels by 240 vertical pixels.\n",
    "# \"\"\"\n",
    "# question=  \"Who developed Nintendo's PPU?\"\n",
    "\n",
    "def get_answer(question,context):\n",
    "    inputs = tokenizer.encode_plus(question, context, add_special_tokens=True, return_tensors=\"pt\")\n",
    "    input_ids = inputs[\"input_ids\"].tolist()[0]\n",
    "    text_tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "    model_inputs = inputs\n",
    "    del model_inputs['token_type_ids']\n",
    "    output = model(**model_inputs)\n",
    "\n",
    "    answer_start_scores, answer_end_scores,_ = model(**inputs)\n",
    "\n",
    "    answer_start = torch.argmax(\n",
    "        answer_start_scores\n",
    "    )  # Get the most likely beginning of answer with the argmax of the score\n",
    "    answer_end = torch.argmax(answer_end_scores) + 1  # Get the most likely end of answer with the argmax of the score\n",
    "\n",
    "    answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[answer_start:answer_end]))\n",
    "    return answer\n",
    "\n",
    "# print(f\"Question: {question}\")\n",
    "# print(f\"Answer: {answer}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 125/5013 [00:08<05:00, 16.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122 Which journalist considered Spectre the worst James Bond movie in three decades?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 443/5013 [00:27<04:14, 17.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "439 Which writer for the San Francisco Chronicle awarded Spectre with a perfect score?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 604/5013 [00:37<03:55, 18.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "601 Who did Ü-Tsang king have an alliance with?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 1805/5013 [01:50<02:54, 18.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1802 What word literally mens \"ancestor?\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 1861/5013 [01:53<03:27, 15.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1859 What word literally means \"warding off evil?\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 2031/5013 [02:03<02:24, 20.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2029 What year did the fifth  series start?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 2348/5013 [02:22<03:05, 14.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2346 Who took control of the whole of Central Tibet?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 4037/5013 [04:04<00:45, 21.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4035 To whom was Eclogue 4 addressed to?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▋ | 4336/5013 [04:22<00:37, 18.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4332 Who thought Burke was prophetic about the French revolution's consequences?\n",
      "4336 During daytime how high can the temperatures reach?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5013/5013 [05:01<00:00, 16.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1 score 0.7506395323328671\n",
      "Number of huge paras:  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "my_df = pd.read_csv('/home/vp.shivasan/interiit/data/Task2dataSet_test.csv')\n",
    "F1s = []\n",
    "n_big_para = 0\n",
    "for i in tqdm(range(len(my_df))):\n",
    "    question = my_df['question'][i]\n",
    "    context = my_df['context'][i]\n",
    "    correct_answer = ast.literal_eval(my_df['answers'][i])['text'][0]\n",
    "    try:\n",
    "        predicted_answer = get_answer(question=question,context=context)\n",
    "    except:\n",
    "        print(i,question)\n",
    "        n_big_para+=1\n",
    "        continue\n",
    "    # predicted_answer = question_answerer(question=question, context=context)['answer']\n",
    "    F1s.append(compute_f1(correct_answer,predicted_answer))\n",
    "\n",
    "print(\"Average F1 score\",np.mean(F1s))\n",
    "print(\"Number of huge paras: \",n_big_para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 384])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load from automodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /home/vp.shivasan/interiit/task2/training_dir/task2_MiniLM-mod_50epochs_2e-5_FINAL_ES/checkpoint-5076 were not used when initializing BertModel: ['MiniLM.encoder.layer.2.output.dense.bias', 'MiniLM.encoder.layer.9.intermediate.dense.bias', 'MiniLM.encoder.layer.8.attention.self.value.weight', 'MiniLM.encoder.layer.7.intermediate.dense.bias', 'MiniLM.encoder.layer.1.attention.self.query.weight', 'MiniLM.encoder.layer.0.attention.output.dense.bias', 'MiniLM.encoder.layer.9.attention.self.key.weight', 'MiniLM.encoder.layer.10.attention.output.dense.bias', 'MiniLM.encoder.layer.7.output.LayerNorm.bias', 'MiniLM.encoder.layer.7.output.dense.bias', 'MiniLM.encoder.layer.0.attention.self.value.bias', 'MiniLM.encoder.layer.7.attention.self.value.weight', 'MiniLM.encoder.layer.7.attention.self.query.weight', 'MiniLM.encoder.layer.2.attention.output.dense.bias', 'MiniLM.encoder.layer.11.intermediate.dense.weight', 'MiniLM.encoder.layer.2.attention.self.value.weight', 'MiniLM.encoder.layer.4.output.LayerNorm.weight', 'MiniLM.encoder.layer.3.attention.self.key.bias', 'MiniLM.encoder.layer.8.output.LayerNorm.weight', 'MiniLM.encoder.layer.9.attention.output.dense.weight', 'MiniLM.encoder.layer.0.output.LayerNorm.bias', 'MiniLM.encoder.layer.8.attention.self.value.bias', 'MiniLM.encoder.layer.3.attention.output.dense.bias', 'MiniLM.encoder.layer.10.output.dense.bias', 'MiniLM.encoder.layer.6.output.LayerNorm.bias', 'MiniLM.encoder.layer.4.intermediate.dense.weight', 'MiniLM.encoder.layer.10.intermediate.dense.weight', 'MiniLM.encoder.layer.3.output.LayerNorm.weight', 'MiniLM.encoder.layer.5.output.dense.bias', 'MiniLM.encoder.layer.5.attention.self.value.bias', 'MiniLM.encoder.layer.2.attention.self.key.weight', 'MiniLM.encoder.layer.7.attention.output.LayerNorm.weight', 'MiniLM.encoder.layer.1.attention.self.value.weight', 'MiniLM.encoder.layer.3.attention.output.dense.weight', 'MiniLM.encoder.layer.4.attention.self.key.bias', 'MiniLM.encoder.layer.10.attention.self.key.weight', 'MiniLM.encoder.layer.4.attention.self.query.weight', 'MiniLM.encoder.layer.1.attention.output.LayerNorm.weight', 'MiniLM.encoder.layer.11.output.LayerNorm.bias', 'MiniLM.encoder.layer.7.attention.self.key.bias', 'MiniLM.encoder.layer.6.output.dense.bias', 'MiniLM.encoder.layer.2.attention.self.key.bias', 'MiniLM.encoder.layer.6.intermediate.dense.weight', 'MiniLM.encoder.layer.8.attention.self.key.bias', 'MiniLM.encoder.layer.1.attention.output.dense.bias', 'MiniLM.encoder.layer.9.output.LayerNorm.bias', 'MiniLM.encoder.layer.10.output.LayerNorm.weight', 'MiniLM.encoder.layer.11.attention.self.key.weight', 'MiniLM.encoder.layer.4.attention.self.value.weight', 'MiniLM.encoder.layer.5.attention.self.query.weight', 'MiniLM.encoder.layer.10.attention.self.value.bias', 'MiniLM.encoder.layer.3.attention.self.value.bias', 'MiniLM.encoder.layer.5.output.dense.weight', 'MiniLM.encoder.layer.7.attention.output.dense.bias', 'MiniLM.encoder.layer.1.output.LayerNorm.bias', 'MiniLM.encoder.layer.2.output.dense.weight', 'MiniLM.encoder.layer.8.attention.output.LayerNorm.bias', 'MiniLM.encoder.layer.10.output.dense.weight', 'MiniLM.encoder.layer.9.output.dense.bias', 'MiniLM.encoder.layer.4.attention.output.dense.bias', 'MiniLM.encoder.layer.5.attention.output.dense.weight', 'MiniLM.encoder.layer.5.output.LayerNorm.weight', 'MiniLM.encoder.layer.10.attention.output.LayerNorm.weight', 'MiniLM.embeddings.position_ids', 'MiniLM.embeddings.LayerNorm.weight', 'MiniLM.encoder.layer.2.intermediate.dense.bias', 'MiniLM.encoder.layer.5.output.LayerNorm.bias', 'MiniLM.encoder.layer.0.output.dense.bias', 'MiniLM.encoder.layer.11.attention.output.dense.bias', 'MiniLM.encoder.layer.8.attention.output.dense.bias', 'MiniLM.encoder.layer.0.attention.output.dense.weight', 'MiniLM.encoder.layer.7.attention.output.LayerNorm.bias', 'MiniLM.embeddings.LayerNorm.bias', 'MiniLM.encoder.layer.0.attention.output.LayerNorm.weight', 'MiniLM.encoder.layer.8.output.LayerNorm.bias', 'MiniLM.encoder.layer.1.attention.self.value.bias', 'MiniLM.encoder.layer.6.output.dense.weight', 'MiniLM.encoder.layer.9.attention.output.LayerNorm.bias', 'MiniLM.encoder.layer.4.attention.output.LayerNorm.weight', 'MiniLM.encoder.layer.11.output.LayerNorm.weight', 'MiniLM.encoder.layer.5.attention.output.LayerNorm.weight', 'qa_outputs.bias', 'MiniLM.encoder.layer.3.attention.output.LayerNorm.weight', 'MiniLM.encoder.layer.11.attention.self.value.weight', 'MiniLM.encoder.layer.6.attention.self.key.weight', 'MiniLM.encoder.layer.1.intermediate.dense.weight', 'MiniLM.encoder.layer.2.attention.self.query.weight', 'MiniLM.encoder.layer.3.intermediate.dense.weight', 'MiniLM.encoder.layer.4.output.LayerNorm.bias', 'MiniLM.encoder.layer.6.attention.self.query.weight', 'MiniLM.encoder.layer.4.attention.self.value.bias', 'MiniLM.encoder.layer.7.attention.output.dense.weight', 'qa_outputs.weight', 'MiniLM.encoder.layer.3.attention.self.query.bias', 'MiniLM.encoder.layer.9.attention.self.query.bias', 'MiniLM.encoder.layer.7.output.LayerNorm.weight', 'MiniLM.encoder.layer.6.attention.self.query.bias', 'MiniLM.encoder.layer.10.output.LayerNorm.bias', 'MiniLM.encoder.layer.0.attention.self.key.bias', 'MiniLM.encoder.layer.2.attention.self.query.bias', 'MiniLM.encoder.layer.4.attention.output.dense.weight', 'MiniLM.encoder.layer.8.intermediate.dense.bias', 'MiniLM.encoder.layer.9.attention.self.value.weight', 'MiniLM.encoder.layer.5.attention.self.value.weight', 'MiniLM.embeddings.position_embeddings.weight', 'MiniLM.encoder.layer.2.output.LayerNorm.weight', 'MiniLM.encoder.layer.2.attention.output.LayerNorm.weight', 'MiniLM.encoder.layer.3.output.dense.weight', 'MiniLM.encoder.layer.5.attention.self.key.weight', 'MiniLM.encoder.layer.1.output.LayerNorm.weight', 'MiniLM.encoder.layer.10.attention.self.key.bias', 'MiniLM.encoder.layer.6.attention.self.key.bias', 'MiniLM.encoder.layer.9.intermediate.dense.weight', 'MiniLM.encoder.layer.11.output.dense.bias', 'MiniLM.encoder.layer.3.attention.self.key.weight', 'MiniLM.encoder.layer.0.attention.self.query.bias', 'MiniLM.encoder.layer.0.intermediate.dense.weight', 'MiniLM.encoder.layer.0.output.LayerNorm.weight', 'MiniLM.encoder.layer.9.attention.output.dense.bias', 'MiniLM.encoder.layer.6.attention.self.value.bias', 'MiniLM.encoder.layer.1.intermediate.dense.bias', 'MiniLM.encoder.layer.4.attention.self.key.weight', 'MiniLM.encoder.layer.11.attention.self.query.weight', 'MiniLM.encoder.layer.3.output.LayerNorm.bias', 'MiniLM.encoder.layer.5.attention.self.query.bias', 'MiniLM.encoder.layer.3.intermediate.dense.bias', 'MiniLM.encoder.layer.9.output.LayerNorm.weight', 'MiniLM.encoder.layer.0.attention.output.LayerNorm.bias', 'MiniLM.encoder.layer.3.attention.self.query.weight', 'MiniLM.encoder.layer.8.attention.self.query.bias', 'MiniLM.encoder.layer.1.attention.output.dense.weight', 'MiniLM.encoder.layer.1.attention.self.query.bias', 'MiniLM.encoder.layer.0.output.dense.weight', 'MiniLM.encoder.layer.10.attention.self.query.weight', 'MiniLM.encoder.layer.6.intermediate.dense.bias', 'MiniLM.encoder.layer.8.output.dense.bias', 'MiniLM.encoder.layer.11.attention.output.dense.weight', 'MiniLM.encoder.layer.1.attention.self.key.bias', 'MiniLM.encoder.layer.7.output.dense.weight', 'MiniLM.encoder.layer.0.attention.self.query.weight', 'MiniLM.encoder.layer.5.attention.output.LayerNorm.bias', 'MiniLM.encoder.layer.10.attention.self.query.bias', 'MiniLM.encoder.layer.0.attention.self.key.weight', 'MiniLM.encoder.layer.6.attention.output.LayerNorm.weight', 'MiniLM.encoder.layer.10.attention.output.LayerNorm.bias', 'MiniLM.encoder.layer.6.output.LayerNorm.weight', 'MiniLM.encoder.layer.10.intermediate.dense.bias', 'MiniLM.encoder.layer.5.attention.self.key.bias', 'MiniLM.encoder.layer.6.attention.output.LayerNorm.bias', 'MiniLM.pooler.dense.weight', 'MiniLM.encoder.layer.8.attention.output.dense.weight', 'MiniLM.encoder.layer.6.attention.self.value.weight', 'MiniLM.encoder.layer.11.intermediate.dense.bias', 'MiniLM.encoder.layer.4.output.dense.weight', 'MiniLM.encoder.layer.11.output.dense.weight', 'MiniLM.encoder.layer.11.attention.output.LayerNorm.weight', 'MiniLM.embeddings.token_type_embeddings.weight', 'MiniLM.encoder.layer.4.attention.output.LayerNorm.bias', 'MiniLM.encoder.layer.1.attention.self.key.weight', 'MiniLM.encoder.layer.9.attention.self.key.bias', 'MiniLM.encoder.layer.5.intermediate.dense.bias', 'MiniLM.encoder.layer.9.attention.self.value.bias', 'MiniLM.encoder.layer.7.intermediate.dense.weight', 'MiniLM.encoder.layer.11.attention.self.value.bias', 'MiniLM.encoder.layer.2.attention.output.LayerNorm.bias', 'MiniLM.encoder.layer.2.output.LayerNorm.bias', 'MiniLM.encoder.layer.10.attention.self.value.weight', 'MiniLM.encoder.layer.11.attention.output.LayerNorm.bias', 'MiniLM.pooler.dense.bias', 'MiniLM.encoder.layer.8.attention.self.query.weight', 'MiniLM.encoder.layer.3.attention.self.value.weight', 'MiniLM.encoder.layer.7.attention.self.key.weight', 'MiniLM.encoder.layer.8.intermediate.dense.weight', 'MiniLM.encoder.layer.2.intermediate.dense.weight', 'MiniLM.encoder.layer.4.output.dense.bias', 'MiniLM.encoder.layer.7.attention.self.query.bias', 'MiniLM.encoder.layer.9.output.dense.weight', 'MiniLM.encoder.layer.0.intermediate.dense.bias', 'MiniLM.encoder.layer.5.intermediate.dense.weight', 'MiniLM.encoder.layer.9.attention.self.query.weight', 'MiniLM.encoder.layer.0.attention.self.value.weight', 'MiniLM.encoder.layer.10.attention.output.dense.weight', 'MiniLM.encoder.layer.8.attention.output.LayerNorm.weight', 'MiniLM.encoder.layer.4.attention.self.query.bias', 'MiniLM.encoder.layer.6.attention.output.dense.weight', 'MiniLM.encoder.layer.11.attention.self.query.bias', 'MiniLM.encoder.layer.5.attention.output.dense.bias', 'MiniLM.encoder.layer.1.attention.output.LayerNorm.bias', 'MiniLM.encoder.layer.3.attention.output.LayerNorm.bias', 'MiniLM.encoder.layer.4.intermediate.dense.bias', 'MiniLM.encoder.layer.1.output.dense.weight', 'MiniLM.encoder.layer.1.output.dense.bias', 'MiniLM.encoder.layer.11.attention.self.key.bias', 'MiniLM.encoder.layer.7.attention.self.value.bias', 'MiniLM.encoder.layer.3.output.dense.bias', 'MiniLM.encoder.layer.2.attention.output.dense.weight', 'MiniLM.encoder.layer.8.attention.self.key.weight', 'MiniLM.encoder.layer.8.output.dense.weight', 'MiniLM.encoder.layer.9.attention.output.LayerNorm.weight', 'MiniLM.encoder.layer.2.attention.self.value.bias', 'MiniLM.embeddings.word_embeddings.weight', 'MiniLM.encoder.layer.6.attention.output.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertModel were not initialized from the model checkpoint at /home/vp.shivasan/interiit/task2/training_dir/task2_MiniLM-mod_50epochs_2e-5_FINAL_ES/checkpoint-5076 and are newly initialized: ['encoder.layer.1.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.8.output.LayerNorm.bias', 'pooler.dense.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.attention.self.key.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.dense.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.10.attention.self.key.bias', 'embeddings.LayerNorm.weight', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.9.attention.self.query.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.5.attention.self.query.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.11.attention.self.query.bias', 'pooler.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.2.attention.output.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('/home/vp.shivasan/interiit/task2/training_dir/task2_MiniLM-mod_50epochs_2e-5_FINAL_ES/checkpoint-5076')\n",
    "model = AutoModel.from_pretrained('/home/vp.shivasan/interiit/task2/training_dir/task2_MiniLM-mod_50epochs_2e-5_FINAL_ES/checkpoint-5076',local_files_only = True,return_dict = True)\n",
    "config = AutoConfig.from_pretrained('/home/vp.shivasan/interiit/task2/training_dir/task2_MiniLM-mod_50epochs_2e-5_FINAL_ES/checkpoint-5076')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer.encode_plus(question, para, add_special_tokens=True, return_tensors=\"pt\")\n",
    "input_ids = inputs[\"input_ids\"].tolist()[0]\n",
    "text_tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "output = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-2.8435, -0.1767, -0.0284,  ..., -0.9489, -0.6321,  0.9973],\n",
       "         [-1.4692,  0.3385, -1.4302,  ..., -1.0068, -2.2559,  0.5336],\n",
       "         [-2.1760,  0.7128, -1.5751,  ..., -0.0490, -1.0524,  1.2547],\n",
       "         ...,\n",
       "         [ 1.9317, -0.0853,  0.9058,  ..., -0.8918, -0.3346,  0.1205],\n",
       "         [ 1.4556,  1.5898,  2.5926,  ..., -0.3540, -0.2982,  1.9612],\n",
       "         [ 1.2073,  0.6247,  0.2067,  ..., -1.3080, -1.0914,  1.8486]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[-3.7681e-01, -1.0134e-01,  6.8426e-01,  5.6293e-01, -2.6529e-01,\n",
       "          3.2416e-01, -9.0883e-02,  5.4870e-01,  1.5242e-01, -4.8494e-01,\n",
       "         -2.1586e-01,  1.8552e-01,  7.1669e-02, -7.1331e-03,  2.7147e-01,\n",
       "         -3.2243e-01,  1.2285e-01, -3.1309e-02,  4.9929e-01,  1.8394e-01,\n",
       "         -2.9855e-01,  2.1637e-02,  4.3720e-01,  1.7160e-02,  1.3632e-01,\n",
       "          2.9443e-01, -5.1914e-02,  3.5638e-01,  3.3920e-01,  7.1152e-02,\n",
       "         -3.3275e-01,  2.2481e-02,  3.1181e-02,  6.2186e-01, -5.7733e-02,\n",
       "          1.4546e-01,  5.3711e-01, -4.2057e-03, -2.3257e-01, -3.6395e-01,\n",
       "          5.6416e-02,  8.4886e-02, -1.6449e-01,  2.3185e-01, -1.4679e-02,\n",
       "         -7.3197e-02,  5.7399e-01,  3.2530e-02, -1.5200e-01, -4.5346e-04,\n",
       "          2.5226e-01, -6.9449e-01,  3.5551e-01, -1.8140e-01,  2.8185e-01,\n",
       "         -3.1575e-01, -1.8371e-01,  2.1387e-01, -6.7132e-02,  1.4685e-02,\n",
       "          7.7647e-01,  1.4000e-02,  4.0878e-01, -2.1736e-01,  2.2793e-01,\n",
       "          5.5796e-01,  8.0658e-02,  3.9492e-01,  5.8928e-01, -2.7808e-01,\n",
       "          5.5994e-01,  1.2604e-01,  3.8318e-03, -1.5262e-01,  2.1610e-02,\n",
       "         -2.9773e-01,  3.4233e-01, -8.0170e-02, -3.7357e-01,  1.5308e-01,\n",
       "          5.7732e-01,  2.9687e-01,  2.1011e-02, -3.3660e-01,  2.7573e-01,\n",
       "         -1.0801e-01,  1.5071e-01,  1.6721e-02,  4.1004e-01, -1.3883e-01,\n",
       "         -1.0851e-01, -3.6790e-01, -1.9558e-01, -5.6395e-01, -6.0747e-01,\n",
       "         -7.6802e-02,  6.9886e-01,  4.8867e-01, -2.9237e-01,  3.5951e-01,\n",
       "         -4.6932e-01,  2.6122e-01, -1.6850e-01,  8.6205e-02, -1.2940e-01,\n",
       "         -1.8480e-01,  4.4615e-01, -2.5189e-01,  4.4373e-01,  1.5912e-02,\n",
       "          5.7324e-01, -5.8834e-01,  1.9047e-01, -1.9866e-01,  4.3272e-04,\n",
       "         -2.0481e-01,  3.6144e-01,  4.0840e-01,  7.0071e-01, -1.5053e-01,\n",
       "         -4.0385e-02, -3.8165e-02, -1.2335e-01,  2.0014e-01,  1.0441e-01,\n",
       "         -4.1784e-01, -1.8819e-01, -1.5458e-01,  2.2203e-01, -3.4542e-01,\n",
       "         -2.5467e-01,  1.9057e-02,  5.9093e-01, -2.6485e-01,  9.8912e-02,\n",
       "         -5.2297e-03,  5.3977e-02,  5.7263e-01,  2.0300e-01, -2.8446e-01,\n",
       "          3.3050e-01, -2.5690e-02,  3.9666e-01, -1.4712e-01, -1.5530e-01,\n",
       "         -3.0089e-02, -6.7321e-01, -5.4121e-01, -1.3610e-01,  6.5966e-02,\n",
       "         -3.2364e-02,  1.0167e-01,  6.6957e-02, -4.9226e-01,  4.9642e-01,\n",
       "          1.7016e-01, -5.0103e-01, -3.8180e-02, -1.0869e-01, -2.7827e-01,\n",
       "         -3.0432e-01,  6.8639e-01, -4.7304e-01, -5.7021e-01, -2.8723e-02,\n",
       "         -1.7063e-01,  4.8756e-02,  1.5617e-01, -1.5956e-01,  4.4001e-01,\n",
       "          2.9391e-01,  1.8215e-01, -3.0523e-01, -2.6560e-01,  4.4815e-01,\n",
       "         -9.9611e-02,  5.2464e-01,  2.1599e-01,  1.9001e-01, -6.7383e-02,\n",
       "         -8.9061e-02, -3.6868e-01, -2.7288e-01,  6.7430e-01, -6.7547e-01,\n",
       "          1.8510e-01,  6.7230e-02, -4.2845e-03, -3.8466e-01,  2.1777e-01,\n",
       "          2.5100e-01, -2.7187e-01,  2.7112e-01, -1.4476e-01, -5.9344e-01,\n",
       "         -4.8685e-02,  1.4418e-01, -2.6867e-01, -5.5349e-01, -4.4148e-01,\n",
       "          7.1709e-01, -4.3831e-01, -3.6668e-01,  2.5136e-02,  4.1810e-02,\n",
       "          3.4587e-01, -2.6031e-01, -4.0367e-01, -1.6416e-01, -3.0517e-01,\n",
       "          1.5839e-01, -4.2306e-01, -4.7212e-01,  3.9761e-01, -3.1584e-01,\n",
       "          1.1862e-01,  4.2063e-01, -4.8597e-01,  8.5273e-02,  1.0525e-02,\n",
       "         -4.3967e-01, -1.9842e-01,  3.3009e-01, -6.7144e-01,  5.5343e-01,\n",
       "          3.1431e-01, -1.4558e-01, -4.2118e-01, -7.3679e-01,  1.8163e-01,\n",
       "         -7.1260e-02,  1.2137e-01,  1.0784e-01,  4.2410e-01, -3.1674e-01,\n",
       "         -1.9416e-01,  2.4716e-01,  4.6552e-01, -5.3331e-01,  7.3482e-01,\n",
       "          3.2413e-01, -3.5216e-01,  3.5774e-01,  5.9692e-01, -1.2027e-01,\n",
       "         -8.2835e-02, -9.5346e-02, -5.7657e-01,  3.0803e-01,  3.5565e-01,\n",
       "          1.9228e-01,  7.0998e-02, -2.3054e-02,  2.8627e-01, -7.3409e-02,\n",
       "         -1.1419e-02,  2.1023e-01, -2.2232e-01,  6.1616e-03,  1.4319e-01,\n",
       "         -1.9760e-01, -1.8441e-01, -2.4174e-01,  1.5880e-01,  7.7354e-02,\n",
       "          4.8823e-01,  1.2636e-01,  3.7280e-01, -1.3978e-01,  4.3137e-01,\n",
       "         -6.8285e-01,  5.1436e-01, -1.6169e-01, -2.9816e-01, -4.7126e-01,\n",
       "          6.7370e-01, -4.8799e-01, -2.4607e-01, -1.1480e-01, -4.2032e-01,\n",
       "          4.5125e-02,  6.9149e-02, -6.0759e-01, -2.7029e-01,  6.4427e-01,\n",
       "         -1.3315e-01,  3.4561e-01, -3.4600e-01,  1.8150e-01,  9.8175e-02,\n",
       "         -4.2337e-02, -1.4430e-01, -2.9124e-01,  3.8258e-01,  5.6495e-01,\n",
       "          2.0401e-01, -4.6903e-01,  2.7302e-01, -2.0637e-01, -1.7437e-01,\n",
       "         -1.8255e-01,  3.8310e-01, -4.4240e-01, -2.2289e-02,  4.4643e-02,\n",
       "         -3.1115e-01,  8.2006e-02,  3.9338e-02, -2.4076e-02,  3.7748e-01,\n",
       "         -1.1979e-01,  1.3678e-01, -7.4607e-01, -5.0306e-01,  3.1826e-01,\n",
       "          1.7494e-01, -1.1771e-01, -3.0750e-01,  4.3966e-02, -3.4660e-01,\n",
       "          2.9137e-01,  4.1261e-01, -5.4181e-01, -2.4612e-01, -6.7472e-02,\n",
       "          6.2710e-01, -7.5422e-01, -4.2367e-01,  2.0920e-01, -4.3276e-01,\n",
       "         -8.5295e-01,  4.3222e-01,  3.0784e-01, -1.7220e-01,  6.3342e-02,\n",
       "         -1.3649e-01,  1.6818e-01, -1.9155e-01, -5.5915e-01, -1.6752e-01,\n",
       "         -4.5754e-01, -5.9772e-01,  6.2197e-02, -3.3985e-02, -7.6207e-01,\n",
       "          2.2508e-01,  3.8608e-01, -2.6114e-01,  5.7421e-01, -4.6398e-02,\n",
       "         -9.5370e-02, -4.4162e-02,  1.5965e-01, -3.2710e-01,  6.9371e-01,\n",
       "         -1.3743e-01,  1.7218e-01, -3.3432e-01, -1.8885e-01, -2.7769e-01,\n",
       "         -3.3532e-01, -3.4553e-01, -1.1074e-01,  1.3067e-02, -1.3765e-01,\n",
       "         -2.4808e-01, -1.9257e-01, -1.8747e-01, -1.0282e-01, -1.9890e-02,\n",
       "         -2.8712e-01, -3.2163e-01,  9.4171e-02, -5.1615e-01,  7.2523e-01,\n",
       "         -4.8234e-01,  5.5426e-01, -2.7452e-01,  3.6019e-01, -6.8866e-02,\n",
       "          4.0946e-01,  2.9657e-01, -3.2495e-01, -2.4889e-01]],\n",
       "       grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ChartIE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c7cc60da36afb68029bad98d2c120ef528bc696932aa2b6711f6174fe2cafae2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
